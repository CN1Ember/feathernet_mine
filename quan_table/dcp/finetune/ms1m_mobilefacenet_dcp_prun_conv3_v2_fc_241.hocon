# ------------- general options ----------------------------------------
save_path = "./insightface_dcp_log/fine-tuning_with_fc/" # log path
data_path = "/mnt/ssd/faces/faces_emore/" # path for dataset folder
dataset = "ms1m_v2"  # options: imagenet | cifar10
seed = 1  # manually set RNG seed
gpu = "2,3"  # GPU id to use, e.g. "0,1,2,3"
print_frequency = 10

# ------------- data options -------------------------------------------
n_threads = 16  # number of threads used for data loading
n_classes = 0  # number of classes in the dataset

# ------------- common optimization options ----------------------------
batch_size = 512  # mini-batch size
momentum = 0.9  # momentum
weight_decay = 5e-4  # weight decay
lr = 0.01  # initial learning rate
n_epochs = 28  # number of total epochs
step = [6,12,18,24]  # multi-step for linear learning rate
warmup_n_epochs = 0  # number of warm up epochs
warmup_lr = 0.01  # warm up learning rate
cos_lr = False

# ------------- model options ------------------------------------------
net_type = "mobilefacenet_v1"  # options: resnet | preresnet
depth = 0                      # resnet depth: (n-2)%6==0
embedding_size = 128
experiment_id = "20190603_conv3_fc_p0.25_98.87"     # experiment identifier

# ------------- resume or retrain options ------------------------------
# dcp_0.25_continues_fc: 0_auxnet_val_lfw_acc =0.9888, 1_auxnet_val_lfw_acc =0.9900, 2_auxnet_val_lfw_acc =98.87
pretrained = "/home/xiezheng/program2019/insightface_DCP/dcp/insightface_dcp_log/channel_pruning_with_fc/log_cs_mobilefacenet_v1_d0_ms1m_v2_bs256_n2_p0.250_lr0.001_20190604_prun_conv3_continues_fc/check_point/model_003_cs_000.pth"
resume = "" # resume checkpoint