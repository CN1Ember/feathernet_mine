# ------------- general options ----------------------------------------
save_path = "./insightface_dcp_log/int8-fine-tuning/" # log path
data_path = "/mnt/ssd/Datasets/faces/faces_emore" # path for dataset folder
dataset = "ms1m_v2"  # options: imagenet | cifar10
seed = 1  # manually set RNG seed
gpu = "2,3"  # GPU id to use, e.g. "0,1,2,3"
print_frequency = 10

# ------------- data options -------------------------------------------
n_threads = 8  # number of threads used for data loading
n_classes = 0  # number of classes in the dataset

# ------------- common optimization options ----------------------------
batch_size = 256  # mini-batch size
momentum = 0.9  # momentum
weight_decay = 4e-5  # weight decay
lr = 0.01  # initial learning rate
n_epochs = 36  # number of total epochs
step = []  # multi-step for linear learning rate
warmup_n_epochs = 0  # number of warm up epochs
warmup_lr = 0.01  # warm up learning rate
cos_lr = True

# ------------- model options ------------------------------------------
net_type = "mobilefacenet_v1_p0.5"  # options: resnet | preresnet
depth = 0                           # resnet depth: (n-2)%6==0
embed_size = 128
experiment_id = "p0.5_cos_lr_w_a_int8_finetune_20190723"     # experiment identifier

# ------------- resume or retrain options ------------------------------
# dcp_0.5_finetuned, val_lfw_acc =0.9945, val_cfp_acc =0.9059, age_acc =0.9523
pretrained = "/home/xiezheng/programs2019/insightface_DCP/dcp/insightface_dcp_log/log_ft_mobilefacenet_v1_ms1m_v2_bs768_e28_lr0.010_step[6, 12, 18, 24]_20190603_conv3_p0.5_97.00_cos_lr/checkpoint_026.pth"
resume = "" # resume checkpoint